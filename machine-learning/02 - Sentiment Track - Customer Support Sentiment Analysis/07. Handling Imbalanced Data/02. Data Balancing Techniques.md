# Module 7: Handling Imbalanced Data

## Task: Apply Oversampling or Undersampling Techniques to Balance the Sentiment Labels

In this task, we will explore strategies to handle imbalanced sentiment classes in the dataset. Imbalanced data occurs when the distribution of classes in the dataset is uneven, and one class has significantly more samples than the others. This can lead to biased model training and poor performance on the minority class. To address this issue, we can employ oversampling or undersampling techniques to balance the sentiment labels.

### 1. Understand the Imbalance in the Dataset

Before applying any balancing technique, it's important to understand the class distribution in the dataset. We can analyze the distribution of sentiment labels to determine the level of imbalance. Let's start by loading the labeled dataset and examining the class distribution.

```python
# Import necessary libraries
import pandas as pd

# Load the labeled dataset
dataset = pd.read_csv('labeled_dataset.csv')

# Check the class distribution
sentiment_counts = dataset['sentiment'].value_counts()
print(sentiment_counts)
```

The output will display the number of samples for each sentiment label. For example:

```
positive    500
neutral     3000
negative    200
Name: sentiment, dtype: int64
```

Based on the class distribution, we can observe that the "neutral" class is significantly overrepresented compared to the "positive" and "negative" classes.

### 2. Undersampling Technique: Random Undersampling

Undersampling involves reducing the number of samples in the majority class to match the minority class. One common undersampling technique is random undersampling, where we randomly select a subset of samples from the majority class.

Let's demonstrate how to perform random undersampling using the `imbalanced-learn` library in Python:

```python
# Import necessary libraries
from imblearn.under_sampling import RandomUnderSampler

# Separate features and labels
X = dataset['message']
y = dataset['sentiment']

# Initialize the random undersampler
undersampler = RandomUnderSampler(random_state=42)

# Perform random undersampling
X_undersampled, y_undersampled = undersampler.fit_resample(X, y)

# Check the new class distribution
undersampled_counts = pd.Series(y_undersampled).value_counts()
print(undersampled_counts)
```

In this code snippet, we first separate the features (`X`) and labels (`y`) from the dataset. We then initialize the `RandomUnderSampler` with a random state for reproducibility. Next, we use the `fit_resample` method to perform random undersampling on the dataset. Finally, we display the new class distribution after undersampling.

### 3. Oversampling Technique: Random Oversampling

Oversampling involves increasing the number of samples in the minority class to balance the dataset. Random oversampling is a simple technique where we randomly duplicate samples from the minority class until the class distribution is balanced.
