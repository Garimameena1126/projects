# Module 3: Model Training and Evaluation

## Task: Splitting the Dataset for Model Evaluation

In this task, we will split the dataset into training and testing sets. The training set will be used to train the machine learning model, while the testing set will be used to evaluate its performance. Splitting the dataset allows us to simulate the model's performance on unseen data and assess its generalization capabilities.

### Step 1: Import the Required Libraries

Before we start splitting the dataset, let's import the necessary libraries that we'll be using throughout this task.

```python
import pandas as pd
from sklearn.model_selection import train_test_split
```

Here, we have imported `pandas` for data manipulation and `train_test_split` from `sklearn.model_selection` module for splitting the dataset.

### Step 2: Load and Prepare the Dataset

First, we need to load the dataset that we gathered and prepared in the previous module. Ensure that you have the dataset file available or adjust the code accordingly to load the dataset from a different source.

```python
# Load the dataset
dataset = pd.read_csv('dataset.csv')

# Perform any necessary data preparation steps
# (e.g., handling missing values, removing duplicates, addressing outliers)
# if not already done in Module 1: Data Collection and Preparation
```

Make sure to replace `'dataset.csv'` with the actual file path or URL of your dataset.

### Step 3: Split the Dataset

Next, we will split the dataset into training and testing sets using the `train_test_split` function. This function randomly divides the data into two subsets based on the specified test size or train size. In our case, we will set aside a portion of the data (e.g., 20%) for testing, while the rest will be used for training the model.

```python
# Split the dataset into features (X) and target variable (y)
X = dataset.drop('churn', axis=1)  # Assuming 'churn' is the target variable column
y = dataset['churn']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

Here, we split the dataset into features (`X`) and the target variable (`y`). Adjust the `drop` function parameters according to your dataset structure, ensuring that the target variable column is excluded from the features. Set the `test_size` parameter to the desired proportion (e.g., 0.2 for 20% test size) and adjust the `random_state` for reproducibility.

After running this code, the dataset will be divided into four sets:
- `X_train`: Training features
- `X_test`: Testing features
- `y_train`: Training target variable
- `y_test`: Testing target variable

### Step 4: Verify the Split

To ensure that the dataset has been split correctly, let's check the shapes of the resulting datasets:

```python
# Print the shapes of the datasets
print("Training set - Features:", X_train.shape)
print("Training set - Target variable:", y_train.shape)
print("Testing set - Features:", X_test.shape)
print("Testing set - Target variable:", y_test.shape)
```

Running this code will display the shapes of the training and testing datasets.

### Step 5: Conclusion

In this task, we successfully split the dataset into training and testing sets, which will be used for model evaluation in subsequent steps. The training set (`X_train` and `y_train`) will be used to train the model, while the testing set (`X_test` and `y_test`) will

 be used to assess its performance.

Next, we will proceed to the next task, where we will choose a classification algorithm and train it on the training data.
