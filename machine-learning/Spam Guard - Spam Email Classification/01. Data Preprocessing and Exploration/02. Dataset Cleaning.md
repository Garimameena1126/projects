# Data Cleaning for Email Classification

In this task, we will perform data cleaning on a labeled dataset of spam and non-spam emails. Data cleaning is an essential step in preparing the data for machine learning models. We will focus on removing unnecessary characters, converting text to lowercase, and removing stop words. Following these steps will help improve the quality of the dataset and enhance the performance of the email classification model.

Let's get started with the data cleaning process.

## Step 1: Load the Dataset

First, we need to load the labeled dataset of spam and non-spam emails. The dataset should be in a format that allows us to access the email content and its corresponding label. For example, a common format is a CSV file with two columns: "email" and "label", where "email" contains the text of the email and "label" indicates whether it is spam or not.

```python
import pandas as pd

# Load the dataset from a CSV file
dataset = pd.read_csv('emails.csv')

# Display the first few rows of the dataset
print(dataset.head())
```

Make sure to replace `'emails.csv'` with the path to your actual dataset file.

## Step 2: Remove Unnecessary Characters

Email texts often contain special characters, punctuation marks, and symbols that do not contribute significantly to the classification task. We will remove these unnecessary characters to clean the text data.

```python
import re

def remove_special_characters(text):
    # Remove special characters and symbols
    cleaned_text = re.sub(r'[^a-zA-Z\s]', '', text)
    return cleaned_text
```

The `remove_special_characters` function uses regular expressions to match any non-alphabetic character or whitespace and replaces them with an empty string.

## Step 3: Convert Text to Lowercase

To ensure consistency and avoid treating the same word differently due to capitalization, we will convert all the text to lowercase.

```python
def convert_to_lowercase(text):
    # Convert text to lowercase
    lowercased_text = text.lower()
    return lowercased_text
```

The `convert_to_lowercase` function simply applies the `lower()` method to the input text.

## Step 4: Remove Stop Words

Stop words are commonly used words in a language (e.g., "and", "the", "is") that do not carry significant meaning and can be safely removed from the text data. We will remove these stop words to reduce noise in our dataset.

```python
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')

def remove_stop_words(text):
    # Tokenize the text into individual words
    words = text.split()

    # Remove stop words
    stop_words = set(stopwords.words('english'))
    filtered_words = [word for word in words if word.lower() not in stop_words]

    # Reconstruct the text without stop words
    filtered_text = ' '.join(filtered_words)
    return filtered_text
```

The `remove_stop_words` function tokenizes the text into individual words, removes the stop words using NLTK's English stop word list, and reconstructs the text without stop words.

## Step 5: Apply Data Cleaning to the Dataset

Now, we will apply the data cleaning steps to the email dataset. We will create a new column in the dataset to store the cleaned text.

```python
# Apply data cleaning to the 'email' column
dataset['cleaned_email'] = dataset['email'].apply(remove_special_characters)
dataset['cleaned_email'] = dataset['cleaned_email'].apply(convert_to_lowercase)
dataset['cleaned_email'] = dataset['cleaned_email'].apply(remove_stop_words)

# Display the updated dataset
print(dataset.head())
```

The `apply` method is used to apply each data cleaning function (`remove_special_characters`, `convert_to_lowercase`, and `remove_stop_words`) to the 'email' column of the dataset.

