# Training and Evaluating Multiple Classification Models

In this task, we will train and evaluate multiple classification models to compare their performance for sleep quality classification. We will consider three popular models: Logistic Regression, Random Forest, and LSTM. By comparing their performance metrics, we will identify the most accurate model for our sleep quality classification.

## Step 1: Prepare the Data

Before training the models, we need to prepare our dataset for classification. Ensure that you have completed Module 1 and Module 2, which cover data collection, exploration, preprocessing, and feature engineering. These steps are crucial for obtaining clean and meaningful data for training the models.

## Step 2: Split the Data

To compare the performance of different models, we need to split our preprocessed data into training and testing sets. The training set will be used to train the models, while the testing set will be used to evaluate their performance.

We can use the `train_test_split` function from the `sklearn.model_selection` module to split our data. Let's assume our preprocessed data is stored in the variables `X` (features) and `y` (target variable). Here's an example:

```python
from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

In the example above, we used a test size of 0.2, meaning 20% of the data will be reserved for testing, and the remaining 80% will be used for training. Adjust the test size according to your dataset and requirements.

## Step 3: Train the Models

Now, we can proceed to train the three classification models: Logistic Regression, Random Forest, and LSTM.

### Logistic Regression

Logistic Regression is a commonly used linear classification algorithm. It models the probability of a certain class given the input features. We can use the `LogisticRegression` class from the `sklearn.linear_model` module to train a logistic regression model. Here's an example:

```python
from sklearn.linear_model import LogisticRegression

# Create a logistic regression model
logreg = LogisticRegression()

# Train the model
logreg.fit(X_train, y_train)
```

### Random Forest

Random Forest is an ensemble learning algorithm that combines multiple decision trees to make predictions. It can handle both categorical and numerical features and is known for its robustness against overfitting. We can use the `RandomForestClassifier` class from the `sklearn.ensemble` module to train a random forest model. Here's an example:

```python
from sklearn.ensemble import RandomForestClassifier

# Create a random forest model
rf = RandomForestClassifier()

# Train the model
rf.fit(X_train, y_train)
```

### LSTM

Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) that can effectively model sequential data. It is commonly used in natural language processing and time series analysis tasks. To train an LSTM model, we need to use a deep learning library such as TensorFlow or PyTorch. Here's an example using TensorFlow's Keras API:

```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Create an LSTM model
lstm = Sequential()
lstm.add(LSTM(64, input_shape=(timesteps, input_dim)))
lstm.add(Dense(1, activation='sigmoid'))

# Compile the model
lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
lstm.fit(X_train, y_train, epochs=10, batch_size=32)


```

In the example above, we defined an LSTM model with one LSTM layer consisting of 64 units. Adjust the architecture and hyperparameters according to your specific requirements.

## Step 4: Evaluate the Models

After training the models, we need to evaluate their performance using appropriate metrics. Commonly used metrics for classification tasks include accuracy, precision, recall, and F1-score.

We can use the `score` method of each trained model to obtain the accuracy on the testing set. Additionally, we can use the `predict` method to generate predictions and compute other metrics using functions from the `sklearn.metrics` module. Here's an example:

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Evaluate logistic regression model
logreg_acc = logreg.score(X_test, y_test)
logreg_pred = logreg.predict(X_test)
logreg_precision = precision_score(y_test, logreg_pred)
logreg_recall = recall_score(y_test, logreg_pred)
logreg_f1 = f1_score(y_test, logreg_pred)

# Evaluate random forest model
rf_acc = rf.score(X_test, y_test)
rf_pred = rf.predict(X_test)
rf_precision = precision_score(y_test, rf_pred)
rf_recall = recall_score(y_test, rf_pred)
rf_f1 = f1_score(y_test, rf_pred)

# Evaluate LSTM model
lstm_loss, lstm_acc = lstm.evaluate(X_test, y_test)

# Print the evaluation results
print("Logistic Regression:")
print("Accuracy:", logreg_acc)
print("Precision:", logreg_precision)
print("Recall:", logreg_recall)
print("F1-score:", logreg_f1)

print("Random Forest:")
print("Accuracy:", rf_acc)
print("Precision:", rf_precision)
print("Recall:", rf_recall)
print("F1-score:", rf_f1)

print("LSTM:")
print("Accuracy:", lstm_acc)
```

Adjust the evaluation metrics and additional computations based on your specific requirements.

## Step 5: Model Comparison

Now that we have trained and evaluated the models, we can compare their performance to identify the most accurate model for sleep quality classification. Compare the metrics obtained in Step 4 for each model and select the one with the highest accuracy or the most suitable combination of metrics for your project.
