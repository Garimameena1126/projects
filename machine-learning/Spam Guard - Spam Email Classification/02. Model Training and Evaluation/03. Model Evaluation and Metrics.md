
## Evaluate the Model's Performance

After training the machine learning model using the preprocessed training dataset, it is important to assess its performance to understand how well it can classify emails as spam or non-spam. In this task, we will evaluate the model's performance using appropriate metrics such as accuracy, precision, recall, and F1 score.

### Step 1: Load the Preprocessed Test Dataset

Before evaluating the model, we need to load the preprocessed test dataset. This dataset contains a set of labeled emails that were not used during the model training phase. The test dataset will be used to assess the model's performance on unseen data.

```python
# Assuming you have preprocessed test dataset stored in X_test and y_test variables

# Import necessary libraries
import numpy as np

# Convert the preprocessed data into numpy arrays
X_test = np.array(X_test)
y_test = np.array(y_test)
```

### Step 2: Make Predictions using the Trained Model

Next, we will use the trained model to make predictions on the test dataset. The model will classify each email as either spam or non-spam based on its learned patterns from the training phase.

```python
# Assuming you have trained model stored in 'model' variable

# Use the trained model to make predictions on the test dataset
y_pred = model.predict(X_test)
```

### Step 3: Calculate Evaluation Metrics

Once we have the predicted labels (`y_pred`) for the test dataset, we can calculate various evaluation metrics to assess the model's performance.

#### Accuracy

Accuracy measures the proportion of correctly classified emails out of the total number of emails in the test dataset.

```python
# Import necessary libraries
from sklearn.metrics import accuracy_score

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
```

#### Precision

Precision measures the proportion of correctly classified spam emails out of all the emails predicted as spam.

```python
# Import necessary libraries
from sklearn.metrics import precision_score

# Calculate precision
precision = precision_score(y_test, y_pred, pos_label='spam')
```

#### Recall

Recall, also known as sensitivity or true positive rate, measures the proportion of correctly classified spam emails out of all the actual spam emails.

```python
# Import necessary libraries
from sklearn.metrics import recall_score

# Calculate recall
recall = recall_score(y_test, y_pred, pos_label='spam')
```

#### F1 Score

The F1 score is the harmonic mean of precision and recall. It provides a balanced measure of the model's performance by considering both precision and recall.

```python
# Import necessary libraries
from sklearn.metrics import f1_score

# Calculate F1 score
f1 = f1_score(y_test, y_pred, pos_label='spam')
```

### Step 4: Display the Evaluation Results

Finally, we can display the evaluation results to assess the model's performance.

```python
print("Evaluation Results:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
```

By evaluating the model's performance using these metrics, we can gain insights into how well it classifies emails as spam or non-spam. Based on these results, we can determine if any further adjustments or fine-tuning of the model are necessary.
