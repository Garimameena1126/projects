**Module 7: Handling Class Imbalance (Optional)**

In this module, we will address the issue of class imbalance in the dataset. Class imbalance occurs when the distribution of classes in the dataset is uneven, and one class has significantly fewer samples than the other. In the context of customer churn prediction, the churned customers (minority class) may be relatively rare compared to the non-churned customers (majority class). To overcome this class imbalance, we can apply techniques such as oversampling the minority class or undersampling the majority class. These techniques help balance the dataset and improve the performance of the machine learning model in predicting customer churn.

**Step 1: Understanding Class Imbalance**
Before we proceed with addressing class imbalance, let's first understand the class distribution in our dataset. We need to identify the minority class (churned customers) and the majority class (non-churned customers).

```python
# Assuming you have already loaded and preprocessed your dataset

# Count the number of samples in each class
class_counts = dataset['churn'].value_counts()

# Calculate the class imbalance ratio
imbalance_ratio = class_counts[0] / class_counts[1]

# Print the class distribution
print("Class Distribution:")
print("Non-Churned Customers:", class_counts[0])
print("Churned Customers:", class_counts[1])
print("Imbalance Ratio:", imbalance_ratio)
```

**Step 2: Undersampling the Majority Class**
Undersampling involves reducing the number of samples from the majority class to match the number of samples in the minority class. This technique helps balance the dataset by removing some randomly selected instances from the majority class.

```python
from sklearn.utils import resample

# Separate the majority and minority classes
majority_class = dataset[dataset['churn'] == 0]
minority_class = dataset[dataset['churn'] == 1]

# Undersample the majority class
undersampled_majority = resample(majority_class,
                                 replace=False,  # Set to False for undersampling
                                 n_samples=len(minority_class),
                                 random_state=42)

# Combine the undersampled majority class with the minority class
balanced_dataset = pd.concat([undersampled_majority, minority_class])
```

**Step 3: Oversampling the Minority Class**
Oversampling involves increasing the number of samples in the minority class to match the number of samples in the majority class. This technique helps balance the dataset by replicating or generating new instances from the minority class.

```python
from sklearn.utils import resample

# Separate the majority and minority classes
majority_class = dataset[dataset['churn'] == 0]
minority_class = dataset[dataset['churn'] == 1]

# Oversample the minority class
oversampled_minority = resample(minority_class,
                                replace=True,  # Set to True for oversampling
                                n_samples=len(majority_class),
                                random_state=42)

# Combine the oversampled minority class with the majority class
balanced_dataset = pd.concat([majority_class, oversampled_minority])
```

**Step 4: Evaluating the Balanced Dataset**
After applying either undersampling or oversampling, it is important to assess the impact on the class distribution to ensure that the dataset is now balanced.

```python
# Count the number of samples in each class after balancing
class_counts_balanced = balanced_dataset['churn'].value_counts()

# Calculate the class imbalance ratio after balancing
imbalance_ratio_balanced = class_counts_balanced[0] / class_counts_balanced[1]

# Print the balanced class distribution
print("Balanced Class Distribution:")
print("Non-Churned Customers:", class_counts

_balanced[0])
print("Churned Customers:", class_counts_balanced[1])
print("Imbalance Ratio (after balancing):", imbalance_ratio_balanced)
```

**Step 5: Retraining the Model**
Now that we have a balanced dataset, we can retrain our machine learning model using this updated data. The process of retraining the model remains the same as described in the previous modules.

```python
# Assuming you have already split your dataset into training and testing sets

# Retrain the model using the balanced dataset
model.fit(X_train_balanced, y_train_balanced)

# Evaluate the model's performance on the testing data
y_pred = model.predict(X_test)
```
