# Testing the API Functionality using Sample Customer Support Messages

In this guide, we will walk through the process of testing the functionality of the sentiment analysis API by sending sample customer support messages and verifying the accuracy of the sentiment predictions. We will also document the project setup and provide instructions for others to test the deployed API.

## Prerequisites
Before proceeding with the testing, make sure you have completed the following tasks:
- Completed Module 1: Data Collection and Exploration to gather a labeled dataset of customer support messages with sentiment labels.
- Completed Module 2: Text Preprocessing and Feature Extraction to preprocess and vectorize the text data.
- Completed Module 3: Model Training and Evaluation to train a sentiment analysis model.

## Steps

### 1. Start the API Server
Before testing the API, you need to ensure that the sentiment analysis API server is up and running. If you haven't set up the server yet, please refer to the Module 4 guide on API development to set up the backend server using a web framework of your choice, such as Flask or Django.

### 2. Prepare Sample Customer Support Messages
To test the API functionality, you will need a set of sample customer support messages. These messages should be similar to the data used during training and should cover a range of sentiment labels. Prepare a file containing these messages, with each message on a new line. For example, you can create a file named `sample_messages.txt` with the following contents:

```
Thank you for your prompt response.
I'm very frustrated with your service!
This product is amazing.
Could you please assist me with my query?
```

### 3. Send Requests to the API
In this step, we will send HTTP requests to the API endpoint, passing the sample customer support messages for sentiment analysis.

#### Example using cURL
You can use the `curl` command-line tool to send POST requests to the API. Open your terminal and execute the following command:

```bash
curl -X POST -H "Content-Type: application/json" -d @sample_messages.txt http://localhost:8000/analyze
```

Here, we are sending a POST request to the `/analyze` endpoint of the API server running on `localhost` at port `8000`. The `sample_messages.txt` file is used as the input data for the sentiment analysis.

#### Example using Python Requests
If you prefer using Python, you can utilize the `requests` library to send requests to the API. Create a new Python file, for example, `test_api.py`, and use the following code:

```python
import requests

# Read sample messages from file
with open('sample_messages.txt', 'r') as file:
    messages = file.readlines()

# Remove newline characters and create a list of messages
messages = [msg.strip() for msg in messages]

# API endpoint URL
url = 'http://localhost:8000/analyze'

# Send requests for each message
for message in messages:
    payload = {'message': message}
    response = requests.post(url, json=payload)
    sentiment = response.json()['sentiment']
    print(f"Message: {message}\nSentiment: {sentiment}\n")
```

Make sure to replace `'http://localhost:8000/analyze'` with the actual API endpoint URL.

### 4. Verify Sentiment Predictions
After sending the requests to the API, you will receive responses containing the predicted sentiment for each sample message. Verify these predictions against the true labels in the testing dataset.

If you have a separate testing dataset with true labels, compare the predicted sentiments with the true labels to assess the accuracy of the sentiment analysis model. You can calculate various evaluation metrics, such as accuracy, precision, recall, and F1-score, to measure the model's performance.

#### Example Comparison
Suppose you have a testing dataset with the true labels and predictions stored in two separate lists, `true_labels` and `predicted_sentiments`. You can use the following code snippet to compare the two lists:

```python
from sklearn.metrics import classification_report

# Assuming true_labels and predicted_sentiments are available
report = classification_report(true_labels, predicted_sentiments)

print(report)
```

The `classification_report` function from `sklearn.metrics` generates a detailed classification report including precision, recall, F1-score, and support for each sentiment label.

### 5. Document the Project Setup and Test Instructions
To ensure others can test the deployed API, document the project setup and provide instructions for testing. Include the following details:

- Required dependencies and their installation instructions.
- Instructions for setting up the API server.
- Sample customer support messages format and how to prepare them.
- Instructions for sending requests to the API.
- Guidelines for verifying the sentiment predictions and assessing the model's accuracy.

Consider using a README file in your project repository or a dedicated documentation page to provide clear and concise instructions for testing the API.

