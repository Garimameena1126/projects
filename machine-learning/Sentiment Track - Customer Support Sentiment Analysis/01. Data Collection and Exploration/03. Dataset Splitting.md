# Splitting the Dataset into Training and Testing Sets

In this task, we will split the labeled dataset of customer support messages and sentiment labels into separate training and testing sets. The training set will be used to train our sentiment analysis model, while the testing set will be used to evaluate the model's performance.

## Step 1: Import the Required Libraries

Before we begin, let's import the necessary libraries for data manipulation and splitting the dataset.

```python
import pandas as pd
from sklearn.model_selection import train_test_split
```

## Step 2: Load the Dataset

First, we need to load the labeled dataset of customer support messages and sentiment labels into a pandas DataFrame. Make sure the dataset is in a format that can be easily loaded into a DataFrame, such as a CSV or Excel file.

```python
# Load the dataset into a DataFrame
data = pd.read_csv('customer_support_dataset.csv')  # Replace 'customer_support_dataset.csv' with the actual filename
```

## Step 3: Explore the Dataset (Optional)

(Optional) Before splitting the dataset, you can explore its contents to gain insights into the distribution of sentiment labels. This step can help you understand the data better and make informed decisions during model training and evaluation. Here's an example of how you can analyze the sentiment label distribution:

```python
# Analyze the distribution of sentiment labels
sentiment_counts = data['sentiment'].value_counts()
print(sentiment_counts)
```

This code snippet will display the count of each sentiment label in the dataset.

## Step 4: Split the Dataset

Now, we will split the dataset into training and testing sets using the `train_test_split()` function from scikit-learn. This function randomly shuffles the data and divides it into the specified proportions. Typically, a common split ratio is 80% for training and 20% for testing.

```python
# Split the dataset into training and testing sets
train_data, test_data, train_labels, test_labels = train_test_split(data['message'], data['sentiment'], test_size=0.2, random_state=42)
```

In the code above, we passed the 'message' column as the input features (`train_data` and `test_data`) and the 'sentiment' column as the target variable (`train_labels` and `test_labels`). The `test_size` parameter is set to 0.2, indicating that 20% of the data will be used for testing. The `random_state` parameter ensures reproducibility of the split.

## Step 5: Verify the Split

To ensure that the dataset has been split correctly, you can print the sizes of the training and testing sets:

```python
print("Training set size:", len(train_data))
print("Testing set size:", len(test_data))
```

Make sure that the sizes of the training and testing sets match your expectations.

