# Optimization of Model Performance in Hyperparameter Tuning in Flight Forecast - Flight Price Prediction

In this guide, we will focus on optimizing the model performance by tuning hyperparameters in a Flight Forecast - Flight Price Prediction project. Hyperparameters are adjustable parameters that determine the learning process and behavior of a machine learning model. By optimizing these hyperparameters, we can enhance the predictive accuracy and overall performance of our model.

Before we begin, make sure you have a basic understanding of machine learning concepts and familiarity with Python programming. We will be using Python and the scikit-learn library for this project.

## Step 1: Importing Libraries and Loading the Dataset

Let's start by importing the necessary libraries and loading the dataset for our flight price prediction project.

```python
import pandas as pd
from sklearn.model_selection import train_test_split

# Load the dataset
flight_data = pd.read_csv('flight_data.csv')

# Split the dataset into features (X) and target variable (y)
X = flight_data.drop('Price', axis=1)
y = flight_data['Price']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

Make sure to replace `'flight_data.csv'` with the actual path or filename of your dataset.

## Step 2: Choosing a Machine Learning Algorithm

Selecting an appropriate machine learning algorithm is crucial for model performance. In this guide, we will use the Random Forest algorithm, which has proven to be effective for regression tasks like price prediction.

```python
from sklearn.ensemble import RandomForestRegressor

# Create an instance of the Random Forest regressor
rf_model = RandomForestRegressor()
```

## Step 3: Defining Hyperparameters

Now, we need to identify the hyperparameters that can be tuned for our Random Forest model. Some common hyperparameters for the Random Forest algorithm include the number of trees (`n_estimators`), the maximum depth of each tree (`max_depth`), and the minimum number of samples required to split an internal node (`min_samples_split`).

```python
# Define the hyperparameters to be tuned
hyperparameters = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10]
}
```

Feel free to experiment with different values for these hyperparameters based on your dataset and requirements.

## Step 4: Hyperparameter Tuning using Grid Search

Grid Search is a commonly used technique for hyperparameter tuning. It exhaustively searches for the best combination of hyperparameters from a predefined grid of values.

```python
from sklearn.model_selection import GridSearchCV

# Create an instance of GridSearchCV
grid_search = GridSearchCV(rf_model, hyperparameters, cv=5)

# Fit the GridSearchCV instance to the training data
grid_search.fit(X_train, y_train)
```

Here, `cv=5` specifies a 5-fold cross-validation strategy. Adjust the value based on the size of your dataset.

## Step 5: Evaluating the Best Model

Once the Grid Search is complete, we can retrieve the best hyperparameters and evaluate the performance of the model using the test dataset.

```python
# Retrieve the best hyperparameters and model
best_hyperparameters = grid_search.best_params_
best_model = grid_search.best_estimator_

# Evaluate the best model on the test data
y_pred = best_model.predict(X_test)

# Calculate evaluation metrics
from sklearn.metrics import mean_squared_error, mean_absolute_error

mse = mean_squared_error(y_test, y_pred)
mae = mean

_absolute_error(y_test, y_pred)

print("Mean Squared Error:", mse)
print("Mean Absolute Error:", mae)
```

## Step 6: Fine-tuning the Model

If desired, you can further refine the model by performing additional hyperparameter tuning. This involves narrowing down the range of hyperparameter values based on the best results obtained from the initial Grid Search.

```python
# Define a refined grid of hyperparameters
refined_hyperparameters = {
    'n_estimators': [200, 250, 300],
    'max_depth': [10, 12, 15],
    'min_samples_split': [2, 3, 4]
}

# Perform Grid Search with refined hyperparameters
refined_grid_search = GridSearchCV(best_model, refined_hyperparameters, cv=5)
refined_grid_search.fit(X_train, y_train)

# Evaluate the refined model
refined_best_model = refined_grid_search.best_estimator_
y_pred_refined = refined_best_model.predict(X_test)

mse_refined = mean_squared_error(y_test, y_pred_refined)
mae_refined = mean_absolute_error(y_test, y_pred_refined)

print("Refined Model Mean Squared Error:", mse_refined)
print("Refined Model Mean Absolute Error:", mae_refined)
```

You can adjust the refined hyperparameter values based on the initial results and continue the fine-tuning process.
