

## Module 2: Model Training and Evaluation

In this module, we will implement a machine learning algorithm, such as Naive Bayes or Support Vector Machines (SVM), for email classification. We will train the model using the preprocessed training dataset, evaluate its performance using appropriate metrics, and fine-tune its parameters to improve its performance.

### Step 1: Choose a Machine Learning Algorithm

The first step is to choose a machine learning algorithm that is suitable for email classification. For this guide, we will use the Naive Bayes algorithm as an example.

### Step 2: Prepare the Data

Before training the model, we need to prepare the preprocessed training dataset.

```python
# Load the preprocessed training dataset
import pandas as pd

data = pd.read_csv('preprocessed_training_data.csv')

# Separate the features (X) and the target variable (y)
X = data['email_text']
y = data['label']
```

### Step 3: Split the Data into Training and Validation Sets

To evaluate the performance of our model during training, we need to split the data into training and validation sets. The training set will be used to train the model, while the validation set will be used to assess its performance.

```python
from sklearn.model_selection import train_test_split

# Split the data into training and validation sets (80% train, 20% validation)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
```

### Step 4: Feature Extraction

Machine learning algorithms typically operate on numerical features, so we need to convert our text data into a numerical representation. One common approach is to use the bag-of-words model.

```python
from sklearn.feature_extraction.text import CountVectorizer

# Create a CountVectorizer object
vectorizer = CountVectorizer()

# Fit the vectorizer on the training data and transform the training data
X_train_features = vectorizer.fit_transform(X_train)

# Transform the validation data using the fitted vectorizer
X_val_features = vectorizer.transform(X_val)
```

### Step 5: Train the Model

Now we are ready to train our model using the preprocessed training dataset.

```python
from sklearn.naive_bayes import MultinomialNB

# Create a Naive Bayes classifier
classifier = MultinomialNB()

# Train the classifier on the training data
classifier.fit(X_train_features, y_train)
```

### Step 6: Evaluate the Model

Once the model is trained, we need to evaluate its performance using appropriate metrics. In this guide, we will use accuracy as the evaluation metric.

```python
# Predict the labels for the validation data
y_pred = classifier.predict(X_val_features)

# Calculate the accuracy of the model
from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_val, y_pred)
```

### Step 7: Fine-tune the Model

To improve the performance of our model, we can fine-tune its parameters. One common approach is to use cross-validation and grid search to find the best combination of parameter values.

```python
from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {'alpha': [0.1, 1.0, 10.0]}

# Create a grid search object
grid_search = GridSearchCV(classifier, param_grid, cv=5)

# Perform the grid search
grid_search.fit(X_train_features, y_train)

# Get the best parameter values
best_params = grid_search.best_params_
```

###

 Step 8: Train the Final Model

After fine-tuning the model's parameters, we can train the final model using the entire preprocessed training dataset.

```python
# Train the final model using the best parameter values
classifier_final = MultinomialNB(alpha=best_params['alpha'])
classifier_final.fit(X_train_features, y_train)
```

