# Evaluating Model Performance Using Metrics

In this guide, we will focus on evaluating the performance of a trained machine learning model using commonly used metrics such as accuracy, precision, recall, and F1-score. These metrics provide valuable insights into how well the model is performing in predicting sleep quality based on the input features.

Before we proceed, make sure you have already completed the previous modules, including data collection, preprocessing, feature engineering, model selection, and training. The evaluation stage comes after training the model.

Let's get started with evaluating the model's performance!

## Step 1: Load the Test Data

To evaluate the model, we need a separate set of data that the model has not seen during training. This set is commonly referred to as the test set. Load the test dataset that contains sleep-related features and their corresponding sleep quality labels.

```python
# Assuming you have a pandas DataFrame for the test data, 'X_test' for features and 'y_test' for labels

import pandas as pd

# Load the test data
test_data = pd.read_csv('test_data.csv')

# Separate the features and labels
X_test = test_data.drop('sleep_quality', axis=1)
y_test = test_data['sleep_quality']
```

## Step 2: Make Predictions

Using the trained model, make predictions on the test data.

```python
# Assuming you have already trained the model and stored it as 'model'

# Make predictions on the test data
y_pred = model.predict(X_test)
```

## Step 3: Calculate Evaluation Metrics

Now that we have the predicted labels (`y_pred`) and the actual labels (`y_test`), we can calculate various evaluation metrics to assess the model's performance. Let's explore some commonly used metrics:

### Accuracy

Accuracy measures the proportion of correctly predicted sleep quality labels to the total number of instances.

```python
from sklearn.metrics import accuracy_score

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
```

### Precision, Recall, and F1-score

Precision, recall, and F1-score are metrics commonly used in binary classification tasks like sleep quality classification. They provide insights into the model's performance in terms of true positives, true negatives, false positives, and false negatives.

```python
from sklearn.metrics import precision_score, recall_score, f1_score

# Calculate precision
precision = precision_score(y_test, y_pred)
print(f"Precision: {precision:.2f}")

# Calculate recall
recall = recall_score(y_test, y_pred)
print(f"Recall: {recall:.2f}")

# Calculate F1-score
f1 = f1_score(y_test, y_pred)
print(f"F1-score: {f1:.2f}")
```

## Step 4: Analyze the Results

Once you have calculated the evaluation metrics, it's important to analyze the results to gain insights into the model's performance. Here are a few points to consider:

- Accuracy: A high accuracy indicates that the model is predicting sleep quality labels correctly. However, it's important to consider other metrics as well, as accuracy alone may not provide a complete picture.
- Precision: Precision measures the model's ability to correctly identify positive instances (correctly predicting good or poor sleep quality). A high precision indicates that the model is making fewer false positive predictions.
- Recall: Recall, also known as sensitivity or true positive rate, measures the model's ability to correctly identify positive instances out of all actual positive instances. A high recall indicates that the model is making fewer false negative predictions.
- F1-score: F1-score is the harmonic mean of precision and recall. It provides a balance between the two metrics. A high F

1-score indicates a good balance between precision and recall.

By analyzing these metrics, you can gain insights into how well the model is performing in predicting sleep quality labels. It's important to consider the specific requirements and constraints of your project to determine which metrics are most important for your application.
