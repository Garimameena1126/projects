# Module 2: Model Training and Evaluation

In this module, we will implement a machine learning algorithm for email classification. We have already preprocessed our training dataset in Module 1. The goal is to train a model that can accurately classify emails as either spam or non-spam (ham). We will explore two popular algorithms: Naive Bayes and Support Vector Machines (SVM). Follow the steps below to implement the email classification model.

## Step 1: Import Libraries

Before we begin, let's import the necessary libraries for our project:

```python
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn import svm
from sklearn import metrics
```

Here, we import the following libraries:
- `pandas` for data manipulation and analysis.
- `CountVectorizer` from scikit-learn to convert text into numerical feature vectors.
- `train_test_split` to split our dataset into training and testing sets.
- `MultinomialNB` for the Naive Bayes algorithm.
- `svm` for the Support Vector Machines algorithm.
- `metrics` from scikit-learn for evaluating the model's performance.

## Step 2: Load the Preprocessed Dataset

Next, we need to load the preprocessed dataset that we obtained from Module 1. Assuming you have the preprocessed dataset stored in a CSV file named `emails.csv`, use the following code to load the data into a pandas DataFrame:

```python
# Load the preprocessed dataset
data = pd.read_csv('emails.csv')
```

Make sure to adjust the file path if your dataset is stored in a different location.

## Step 3: Split the Dataset

To train and evaluate our model, we need to split the dataset into training and testing sets. The training set will be used to train the model, while the testing set will be used to evaluate its performance. We can use the `train_test_split` function from scikit-learn to accomplish this:

```python
# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.2, random_state=42)
```

Here, we split the dataset such that 80% of the data is used for training (`X_train` and `y_train`), and 20% is used for testing (`X_test` and `y_test`). The `random_state` parameter ensures reproducibility of the split.

## Step 4: Feature Extraction

Before we can train our model, we need to convert the email text into numerical features that the machine learning algorithms can understand. We will use the `CountVectorizer` from scikit-learn to convert the text into a matrix of token counts:

```python
# Create an instance of CountVectorizer
vectorizer = CountVectorizer()

# Fit the vectorizer on the training data and transform the training data into feature vectors
X_train_features = vectorizer.fit_transform(X_train)

# Transform the testing data into feature vectors
X_test_features = vectorizer.transform(X_test)
```

The `fit_transform` method fits the vectorizer on the training data and converts the text into feature vectors. The `transform` method is then used to convert the testing data into feature vectors using the same vocabulary learned from the training data.

## Step 5: Train the Model - Naive Bayes

Now we are ready to train our email classification model. Let's start with the Naive Bayes algorithm. Follow the code below:

```python
# Create an instance of the Naive Bayes classifier
naive_bay

es = MultinomialNB()

# Train the classifier on the training data
naive_bayes.fit(X_train_features, y_train)
```

Here, we create an instance of the `MultinomialNB` classifier and train it using the training data features (`X_train_features`) and corresponding labels (`y_train`).

## Step 6: Train the Model - Support Vector Machines (SVM)

Next, let's train the email classification model using Support Vector Machines (SVM). Use the following code:

```python
# Create an instance of the SVM classifier
svm_classifier = svm.SVC()

# Train the classifier on the training data
svm_classifier.fit(X_train_features, y_train)
```

Similarly to Naive Bayes, we create an instance of the `SVC` classifier and train it using the training data features (`X_train_features`) and labels (`y_train`).

## Step 7: Evaluate the Model

After training our models, it's crucial to evaluate their performance on unseen data. We will use the testing data to evaluate the models and calculate metrics such as accuracy, precision, recall, and F1-score. Add the following code:

```python
# Make predictions on the testing data using Naive Bayes
naive_bayes_predictions = naive_bayes.predict(X_test_features)

# Calculate and print the performance metrics for Naive Bayes
print("Naive Bayes Performance Metrics:")
print("Accuracy:", metrics.accuracy_score(y_test, naive_bayes_predictions))
print("Precision:", metrics.precision_score(y_test, naive_bayes_predictions))
print("Recall:", metrics.recall_score(y_test, naive_bayes_predictions))
print("F1-Score:", metrics.f1_score(y_test, naive_bayes_predictions))

# Make predictions on the testing data using SVM
svm_predictions = svm_classifier.predict(X_test_features)

# Calculate and print the performance metrics for SVM
print("\nSVM Performance Metrics:")
print("Accuracy:", metrics.accuracy_score(y_test, svm_predictions))
print("Precision:", metrics.precision_score(y_test, svm_predictions))
print("Recall:", metrics.recall_score(y_test, svm_predictions))
print("F1-Score:", metrics.f1_score(y_test, svm_predictions))
```

The `predict` method is used to make predictions on the testing data for both Naive Bayes and SVM. Then, various metrics are calculated using the predicted labels and the ground truth labels (`y_test`).

## Step 8: Fine-tune the Model (Optional)

To improve the performance of our models, we can fine-tune their parameters. This process involves selecting the optimal values for the algorithm-specific parameters. Fine-tuning can be done using techniques like grid search or random search. However, the details of fine-tuning are beyond the scope of this guide.

Congratulations! You have successfully implemented the email classification model using Naive Bayes and Support Vector Machines. You trained the models, evaluated their performance, and optionally fine-tuned them. In the next module, we will explore how to deploy the trained model and create a web interface for email classification.

