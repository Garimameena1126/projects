# Train and Evaluate Regression Models

In this module, we will train and evaluate multiple regression models to compare their performance for flight price prediction. We will consider three popular regression models: Linear Regression, Random Forest, and Gradient Boosting. The goal is to identify the most accurate model for predicting flight prices.

## Step 1: Import the Required Libraries

Before we begin, let's import the necessary libraries for our project:

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
```

Make sure you have these libraries installed in your environment before running the code.

## Step 2: Load the Preprocessed Dataset

Assuming you have already completed Module 2 (Data Preprocessing and Feature Engineering), we will use the preprocessed dataset for model training and evaluation. Load the preprocessed dataset into a Pandas DataFrame:

```python
# Load the preprocessed dataset
df = pd.read_csv('preprocessed_data.csv')
```

Replace `'preprocessed_data.csv'` with the filename and path of your preprocessed dataset.

## Step 3: Split the Dataset into Training and Testing Sets

To evaluate the performance of our regression models, we need to split the dataset into training and testing sets. The training set will be used to train the models, while the testing set will be used to evaluate their performance.

```python
# Split the dataset into features (X) and target variable (y)
X = df.drop('flight_price', axis=1)
y = df['flight_price']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

The code above splits the dataset into features (`X`) and the target variable (`y`). We then use the `train_test_split` function from scikit-learn to split `X` and `y` into training and testing sets. We set `test_size=0.2` to allocate 20% of the data for testing and `random_state=42` for reproducibility.

## Step 4: Train and Evaluate the Regression Models

We will now train and evaluate the three regression models: Linear Regression, Random Forest, and Gradient Boosting. Let's start with Linear Regression:

### Linear Regression

```python
# Create a Linear Regression model
linear_model = LinearRegression()

# Train the model
linear_model.fit(X_train, y_train)

# Make predictions on the testing set
linear_predictions = linear_model.predict(X_test)

# Evaluate the model
linear_mae = mean_absolute_error(y_test, linear_predictions)
linear_rmse = mean_squared_error(y_test, linear_predictions, squared=False)

# Print the evaluation metrics
print('Linear Regression:')
print('Mean Absolute Error:', linear_mae)
print('Root Mean Squared Error:', linear_rmse)
```

The code above creates a Linear Regression model, trains it using the training data, makes predictions on the testing set, and evaluates the model's performance using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). The evaluation metrics are then printed for analysis.

### Random Forest

```python
# Create a Random Forest Regression model
rf_model = RandomForestRegressor(random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

# Make predictions on the testing set
rf_predictions = rf_model.predict(X_test)

# Evaluate the model
rf_mae = mean_absolute_error(y_test, rf_predictions)
rf_rmse = mean

_squared_error(y_test, rf_predictions, squared=False)

# Print the evaluation metrics
print('Random Forest Regression:')
print('Mean Absolute Error:', rf_mae)
print('Root Mean Squared Error:', rf_rmse)
```

The code above creates a Random Forest Regression model, trains it using the training data, makes predictions on the testing set, and evaluates the model's performance using MAE and RMSE. The evaluation metrics are then printed for analysis.

### Gradient Boosting

```python
# Create a Gradient Boosting Regression model
gb_model = GradientBoostingRegressor(random_state=42)

# Train the model
gb_model.fit(X_train, y_train)

# Make predictions on the testing set
gb_predictions = gb_model.predict(X_test)

# Evaluate the model
gb_mae = mean_absolute_error(y_test, gb_predictions)
gb_rmse = mean_squared_error(y_test, gb_predictions, squared=False)

# Print the evaluation metrics
print('Gradient Boosting Regression:')
print('Mean Absolute Error:', gb_mae)
print('Root Mean Squared Error:', gb_rmse)
```

The code above creates a Gradient Boosting Regression model, trains it using the training data, makes predictions on the testing set, and evaluates the model's performance using MAE and RMSE. The evaluation metrics are then printed for analysis.

## Step 5: Compare the Model Performances

After evaluating the regression models, we can compare their performance based on the evaluation metrics. Let's summarize the results:

```python
# Create a DataFrame to compare the models
results = pd.DataFrame({
    'Model': ['Linear Regression', 'Random Forest', 'Gradient Boosting'],
    'Mean Absolute Error': [linear_mae, rf_mae, gb_mae],
    'Root Mean Squared Error': [linear_rmse, rf_rmse, gb_rmse]
})

# Print the results
print(results)
```

The code above creates a DataFrame to compare the models' performance using the evaluation metrics. The DataFrame is then printed, displaying the mean absolute error and root mean squared error for each model.

