## Module 1: Data Preprocessing and Exploration

### Task: Splitting the Dataset into Training and Testing Sets

In this task, we will split the labeled dataset of spam and non-spam emails into training and testing sets. The training set will be used to train our machine learning model, while the testing set will be used to evaluate its performance. By splitting the dataset, we can assess how well our model generalizes to unseen data.

#### Step 1: Import the Required Libraries

Before we begin, let's import the necessary libraries for handling and splitting the dataset. In this guide, we will use the `pandas` library for data manipulation and the `scikit-learn` library for splitting the dataset.

```python
import pandas as pd
from sklearn.model_selection import train_test_split
```

#### Step 2: Load the Labeled Dataset

Assuming you have a labeled dataset of spam and non-spam emails in a suitable format (e.g., CSV, Excel), we will load the dataset using `pandas`. Make sure the dataset has a column representing the email content (text) and a column indicating the class label (spam or non-spam).

```python
# Load the dataset
dataset = pd.read_csv('path/to/dataset.csv')
```

#### Step 3: Splitting the Dataset

Now, we will split the dataset into training and testing sets using the `train_test_split` function from `scikit-learn`. We typically allocate a certain percentage of the data for testing, commonly around 20-30%. In this example, we will use an 80-20 split, where 80% of the data will be used for training and 20% for testing.

```python
# Split the dataset into training and testing sets
train_data, test_data, train_labels, test_labels = train_test_split(
    dataset['email_content'],  # Features (email content)
    dataset['label'],  # Labels (spam or non-spam)
    test_size=0.2,  # Percentage of data for testing
    random_state=42  # Set a random seed for reproducibility
)
```

Let's break down the code snippet:

- `dataset['email_content']` represents the feature column containing the email content.
- `dataset['label']` represents the label column containing the class labels.
- `test_size` specifies the percentage of the dataset to be allocated for testing.
- `random_state` is an optional parameter that sets a seed for random number generation, ensuring reproducibility of the split.

After executing this code, the dataset will be divided into four separate variables:
- `train_data`: The training set's email content.
- `test_data`: The testing set's email content.
- `train_labels`: The class labels for the training set.
- `test_labels`: The class labels for the testing set.

#### Step 4: Verify the Split

It's essential to verify that the dataset has been split correctly. We can check the sizes of the training and testing sets to ensure they align with the specified split percentage.

```python
# Print the sizes of the training and testing sets
print("Training set size:", len(train_data))
print("Testing set size:", len(test_data))
```

The output should display the sizes of the training and testing sets, respectively.

#### Step 5: Further Exploration (Optional)

Once the dataset has been split, you can explore each set to gain insights into the distribution of spam and non-spam emails. This step is optional but can provide useful information about the dataset's characteristics.

For example, you can examine the class distribution using `value_counts()` to count the occurrences of each class label:

```python
# Count the

 occurrences of each class label in the training set
print(train_labels.value_counts())
```
